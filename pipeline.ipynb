{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaac4732-3605-420d-9130-934161624a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pip imports\n",
    "#!pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a42a468-dc60-4fa4-b9b1-10a9f6da5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import googletrans\n",
    "from deep_translator import GoogleTranslator\n",
    "import tritonclient.http as httpclient\n",
    "from tritonclient.utils import np_to_triton_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4be6078c-93d2-4a2a-ba01-e75a672835fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take wav file in and convert into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4425140d-44f5-459c-bdef-d65882547d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the wav file:\n",
    "wavefile = \"testing.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "964917c9-5651-43a7-90bb-1908b4a75fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using\n",
    "def take_in_wav(wavefile):\n",
    "    import riva.client\n",
    "    auth = riva.client.Auth(uri='10.100.182.246:50051')\n",
    "    asr_service = riva.client.ASRService(auth)\n",
    "\n",
    "    offline_config = riva.client.RecognitionConfig(\n",
    "        encoding=riva.client.AudioEncoding.LINEAR_PCM,\n",
    "        max_alternatives=1,\n",
    "        enable_automatic_punctuation=True,\n",
    "        verbatim_transcripts=False,\n",
    "    )\n",
    "\n",
    "    my_wav_file = wavefile\n",
    "    riva.client.add_audio_file_specs_to_config(offline_config, my_wav_file)\n",
    "\n",
    "    with open(my_wav_file, 'rb') as fh:\n",
    "        data = fh.read()\n",
    "\n",
    "    response = asr_service.offline_recognize(data, offline_config)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2c29a77-b26a-4e42-8a97-40933673d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_script(response):\n",
    "    x = response.__str__().partition('transcript: ')\n",
    "    x = x[2]\n",
    "    x = x.__str__().partition('\\n')\n",
    "    y = x[0]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f49d6ba-6db6-4419-b269-3a6e9bd514ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = to_script(take_in_wav(speech), \"en-US\")\n",
    "\n",
    "#Outputs a text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af894eb-8a2a-4281-87d7-fc02b4a8a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simplify it using the summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98345ef7-2001-4315-b257-8c5c00f29f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "URL = \"10.98.96.143:8000\"\n",
    "MODEl_GPTJ_FASTERTRANSFORMER = \"ensemble\" \n",
    "\n",
    "OUTPUT_LEN = 128\n",
    "BATCH_SIZE = 1\n",
    "BEAM_WIDTH = 1\n",
    "TOP_K = 20\n",
    "TOP_P = 0.9\n",
    "\n",
    "start_id = 220\n",
    "end_id = 50256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9eb49eb-9fed-4343-94d7-7ac8f44b5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = httpclient.InferenceServerClient(URL, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78076c69-2752-4414-b940-7d5e1c52570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_server_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c4c094d-426d-4dd7-befb-0f099164bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference hyperparameters\n",
    "def prepare_tensor(name, input):\n",
    "    tensor = httpclient.InferInput(\n",
    "        name, input.shape, np_to_triton_dtype(input.dtype))\n",
    "    tensor.set_data_from_numpy(input)\n",
    "    return tensor\n",
    "\n",
    "# explanation\n",
    "def prepare_inputs(input0):\n",
    "    bad_words_list = np.array([[\"intelligence\"]], dtype=object)\n",
    "    stop_words_list = np.array([[\"\"]], dtype=object)\n",
    "    input0_data = np.array(input0).astype(object)\n",
    "    output0_len = np.ones_like(input0).astype(np.uint32) * OUTPUT_LEN\n",
    "    runtime_top_k = (TOP_K * np.ones([input0_data.shape[0], 1])).astype(np.uint32)\n",
    "    runtime_top_p = TOP_P * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    beam_search_diversity_rate = 0.0 * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    temperature = 1.0 * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    len_penalty = 1.0 * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    repetition_penalty = 1.0 * np.ones([input0_data.shape[0], 1]).astype(np.float32)\n",
    "    random_seed = 0 * np.ones([input0_data.shape[0], 1]).astype(np.int32)\n",
    "    is_return_log_probs = True * np.ones([input0_data.shape[0], 1]).astype(bool)\n",
    "    beam_width = (BEAM_WIDTH * np.ones([input0_data.shape[0], 1])).astype(np.uint32)\n",
    "    start_ids = start_id * np.ones([input0_data.shape[0], 1]).astype(np.uint32)\n",
    "    end_ids = end_id * np.ones([input0_data.shape[0], 1]).astype(np.uint32)\n",
    "\n",
    "    inputs = [\n",
    "        prepare_tensor(\"INPUT_0\", input0_data),\n",
    "        prepare_tensor(\"INPUT_1\", output0_len),\n",
    "        prepare_tensor(\"INPUT_2\", bad_words_list),\n",
    "        prepare_tensor(\"INPUT_3\", stop_words_list),\n",
    "        prepare_tensor(\"runtime_top_k\", runtime_top_k),\n",
    "        prepare_tensor(\"runtime_top_p\", runtime_top_p),\n",
    "        prepare_tensor(\"beam_search_diversity_rate\", beam_search_diversity_rate),\n",
    "        prepare_tensor(\"temperature\", temperature),\n",
    "        prepare_tensor(\"len_penalty\", len_penalty),\n",
    "        prepare_tensor(\"repetition_penalty\", repetition_penalty),\n",
    "        prepare_tensor(\"random_seed\", random_seed),\n",
    "        prepare_tensor(\"is_return_log_probs\", is_return_log_probs),\n",
    "        prepare_tensor(\"beam_width\", beam_width),\n",
    "        prepare_tensor(\"start_id\", start_ids),\n",
    "        prepare_tensor(\"end_id\", end_ids),\n",
    "    ]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b39f5c-2be7-489d-ac2d-bf36dd2c4781",
   "metadata": {},
   "outputs": [],
   "source": [
    "input0 = [[input_user],]\n",
    "inputs = prepare_inputs(input0)\n",
    "result = client.infer(MODEl_GPTJ_FASTERTRANSFORMER, inputs)\n",
    "output0 = result.as_numpy(\"OUTPUT_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4175f43c-480f-48ed-ad90-80ddfd1dc5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the summation\n",
    "print(output0[0].decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df996aa3-1097-4912-8f53-c43bc70ef1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d51281d-6963-4e16-937e-077ec388b253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
